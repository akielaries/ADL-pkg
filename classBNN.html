<!-- HTML header for doxygen 1.9.4-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>openGPMP: BNN Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="doxygen-awesome-darkmode-toggle.js"></script>
<script type="text/javascript">
    DoxygenAwesomeDarkModeToggle.init()
    DoxygenAwesomeDarkModeToggle.title = "Toggle Light/Dark Mode"
    DoxygenAwesomeDarkModeToggle.lightModeIcon = 'ðŸŒž'
</script>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="openGPMP_icon_smaller.png"/></td>
  <td id="projectalign">
   <div id="projectname">openGPMP
   </div>
   <div id="projectbrief">Open Source Mathematics Package</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classBNN-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">BNN Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Bayesian Neural Network class.  
 <a href="classBNN.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a6453c5fa070a02120d9058392a1dc054"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN</a> (int <a class="el" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>, int <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, int <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>, double <a class="el" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>=1.0)</td></tr>
<tr class="memdesc:a6453c5fa070a02120d9058392a1dc054"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor for the <a class="el" href="classBNN.html" title="Bayesian Neural Network class.">BNN</a> class.  <a href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">More...</a><br /></td></tr>
<tr class="separator:a6453c5fa070a02120d9058392a1dc054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18c2de8aeb520eb248e5ac8d0b7702dd"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a18c2de8aeb520eb248e5ac8d0b7702dd">fit</a> (const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X_train, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y_train, int epochs=1000)</td></tr>
<tr class="memdesc:a18c2de8aeb520eb248e5ac8d0b7702dd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Train the Bayesian Neural Network.  <a href="classBNN.html#a18c2de8aeb520eb248e5ac8d0b7702dd">More...</a><br /></td></tr>
<tr class="separator:a18c2de8aeb520eb248e5ac8d0b7702dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:add1980ab307e3c21ad1b49baac31bf5f"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict</a> (const std::vector&lt; double &gt; &amp;input_vector)</td></tr>
<tr class="memdesc:add1980ab307e3c21ad1b49baac31bf5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Predict the output for a given input.  <a href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">More...</a><br /></td></tr>
<tr class="separator:add1980ab307e3c21ad1b49baac31bf5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a709d59568bb9986baa79a9fcef808d45"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a> (double x)</td></tr>
<tr class="memdesc:a709d59568bb9986baa79a9fcef808d45"><td class="mdescLeft">&#160;</td><td class="mdescRight">Activation function for the hidden layer.  <a href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">More...</a><br /></td></tr>
<tr class="separator:a709d59568bb9986baa79a9fcef808d45"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8322d4106f20c2a6e472f70db8da94e6"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood</a> ()</td></tr>
<tr class="memdesc:a8322d4106f20c2a6e472f70db8da94e6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the log-likelihood of the prior distribution.  <a href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">More...</a><br /></td></tr>
<tr class="separator:a8322d4106f20c2a6e472f70db8da94e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6c33b682dfa29b864d5ef002d58268fd"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> (const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y)</td></tr>
<tr class="memdesc:a6c33b682dfa29b864d5ef002d58268fd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the log-likelihood of the data.  <a href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">More...</a><br /></td></tr>
<tr class="separator:a6c33b682dfa29b864d5ef002d58268fd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6fac631e4a1c0467e11c8089b72f7b9d"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">compute_loss</a> (const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y)</td></tr>
<tr class="memdesc:a6fac631e4a1c0467e11c8089b72f7b9d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the negative log posterior (loss function)  <a href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">More...</a><br /></td></tr>
<tr class="separator:a6fac631e4a1c0467e11c8089b72f7b9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a190c79edcec186188ef96e30a1b099d9"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights</a> (const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y, double learning_rate)</td></tr>
<tr class="memdesc:a190c79edcec186188ef96e30a1b099d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Update weights using stochastic gradient descent.  <a href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">More...</a><br /></td></tr>
<tr class="separator:a190c79edcec186188ef96e30a1b099d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a279dcd56ad5a75e42c2f39491656db64"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a></td></tr>
<tr class="memdesc:a279dcd56ad5a75e42c2f39491656db64"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of input features.  <a href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">More...</a><br /></td></tr>
<tr class="separator:a279dcd56ad5a75e42c2f39491656db64"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a24f4cd9fa8b68acc0ab88f78e0a433f2"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a></td></tr>
<tr class="memdesc:a24f4cd9fa8b68acc0ab88f78e0a433f2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of hidden units in the network.  <a href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">More...</a><br /></td></tr>
<tr class="separator:a24f4cd9fa8b68acc0ab88f78e0a433f2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acec9954182ed2dfcd18ca2290594a42b"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a></td></tr>
<tr class="memdesc:acec9954182ed2dfcd18ca2290594a42b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Number of output units in the network.  <a href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">More...</a><br /></td></tr>
<tr class="separator:acec9954182ed2dfcd18ca2290594a42b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa2f519827b4b67d66a569bc2c0a5ee7e"><td class="memItemLeft" align="right" valign="top">double&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a></td></tr>
<tr class="memdesc:aa2f519827b4b67d66a569bc2c0a5ee7e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Variance for the prior distribution.  <a href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">More...</a><br /></td></tr>
<tr class="separator:aa2f519827b4b67d66a569bc2c0a5ee7e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a8dbbcda35e722fb044192fd9ce6525"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; double &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a></td></tr>
<tr class="memdesc:a9a8dbbcda35e722fb044192fd9ce6525"><td class="mdescLeft">&#160;</td><td class="mdescRight">Weights from input to hidden layer.  <a href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">More...</a><br /></td></tr>
<tr class="separator:a9a8dbbcda35e722fb044192fd9ce6525"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a018666fad85e1ff23fa4e2130694713a"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a></td></tr>
<tr class="memdesc:a018666fad85e1ff23fa4e2130694713a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Biases for the hidden layer.  <a href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">More...</a><br /></td></tr>
<tr class="separator:a018666fad85e1ff23fa4e2130694713a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa9e8a5c9cea48ca7f5cf36da8806e0d9"><td class="memItemLeft" align="right" valign="top">std::vector&lt; std::vector&lt; double &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a></td></tr>
<tr class="memdesc:aa9e8a5c9cea48ca7f5cf36da8806e0d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Weights from hidden to output layer.  <a href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">More...</a><br /></td></tr>
<tr class="separator:aa9e8a5c9cea48ca7f5cf36da8806e0d9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad873f27be16165a38b4fc674bfd01edd"><td class="memItemLeft" align="right" valign="top">std::vector&lt; double &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a></td></tr>
<tr class="memdesc:ad873f27be16165a38b4fc674bfd01edd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Biases for the output layer.  <a href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">More...</a><br /></td></tr>
<tr class="separator:ad873f27be16165a38b4fc674bfd01edd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7250f3ccdea96a6107f43d9ba45b91e3"><td class="memItemLeft" align="right" valign="top">std::mt19937&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a></td></tr>
<tr class="memdesc:a7250f3ccdea96a6107f43d9ba45b91e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mersenne Twister random number generator.  <a href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">More...</a><br /></td></tr>
<tr class="separator:a7250f3ccdea96a6107f43d9ba45b91e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Bayesian Neural Network class. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00045">45</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a6453c5fa070a02120d9058392a1dc054"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6453c5fa070a02120d9058392a1dc054">&#9670;&nbsp;</a></span>BNN()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">BNN::BNN </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>input_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>hidden_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>output_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>prior_variance</em> = <code>1.0</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor for the <a class="el" href="classBNN.html" title="Bayesian Neural Network class.">BNN</a> class. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_size</td><td>Number of input features </td></tr>
    <tr><td class="paramname">hidden_size</td><td>Number of hidden units in the network </td></tr>
    <tr><td class="paramname">output_size</td><td>Number of output units in the network </td></tr>
    <tr><td class="paramname">prior_variance</td><td>Variance for the prior distribution (default is 1.0) </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00036">36</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;    : <a class="code" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>(in_size), <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>(h_size), <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>(out_size),</div>
<div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;      <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>(p_variance), <a class="code" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>(std::random_device{}()) {</div>
<div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;    <span class="comment">// initialize weights and biases with random values</span></div>
<div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;    std::normal_distribution&lt;double&gt; normal_distribution(0.0, 1.0);</div>
<div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160; </div>
<div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>.resize(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>,</div>
<div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;                                   std::vector&lt;double&gt;(<a class="code" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>));</div>
<div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++i) {</div>
<div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>; ++j) {</div>
<div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;            <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[i][j] = normal_distribution(<a class="code" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>);</div>
<div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;        }</div>
<div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    }</div>
<div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160; </div>
<div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>.resize(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>);</div>
<div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++i) {</div>
<div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;        <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[i] = normal_distribution(<a class="code" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>);</div>
<div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;    }</div>
<div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160; </div>
<div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;    <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>.resize(<a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>,</div>
<div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;                                    std::vector&lt;double&gt;(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>));</div>
<div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++i) {</div>
<div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++j) {</div>
<div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;            <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[i][j] = normal_distribution(<a class="code" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>);</div>
<div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;        }</div>
<div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;    }</div>
<div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160; </div>
<div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>.resize(<a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>);</div>
<div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++i) {</div>
<div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[i] = normal_distribution(<a class="code" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>);</div>
<div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;    }</div>
<div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;}</div>
<div class="ttc" id="aclassBNN_html_a018666fad85e1ff23fa4e2130694713a"><div class="ttname"><a href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">BNN::hidden_biases</a></div><div class="ttdeci">std::vector&lt; double &gt; hidden_biases</div><div class="ttdoc">Biases for the hidden layer.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00105">bayes_net.hpp:105</a></div></div>
<div class="ttc" id="aclassBNN_html_a24f4cd9fa8b68acc0ab88f78e0a433f2"><div class="ttname"><a href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">BNN::hidden_size</a></div><div class="ttdeci">int hidden_size</div><div class="ttdoc">Number of hidden units in the network.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00085">bayes_net.hpp:85</a></div></div>
<div class="ttc" id="aclassBNN_html_a279dcd56ad5a75e42c2f39491656db64"><div class="ttname"><a href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">BNN::input_size</a></div><div class="ttdeci">int input_size</div><div class="ttdoc">Number of input features.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00080">bayes_net.hpp:80</a></div></div>
<div class="ttc" id="aclassBNN_html_a7250f3ccdea96a6107f43d9ba45b91e3"><div class="ttname"><a href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">BNN::rng</a></div><div class="ttdeci">std::mt19937 rng</div><div class="ttdoc">Mersenne Twister random number generator.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00120">bayes_net.hpp:120</a></div></div>
<div class="ttc" id="aclassBNN_html_a9a8dbbcda35e722fb044192fd9ce6525"><div class="ttname"><a href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">BNN::input_to_hidden_weights</a></div><div class="ttdeci">std::vector&lt; std::vector&lt; double &gt; &gt; input_to_hidden_weights</div><div class="ttdoc">Weights from input to hidden layer.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00100">bayes_net.hpp:100</a></div></div>
<div class="ttc" id="aclassBNN_html_aa2f519827b4b67d66a569bc2c0a5ee7e"><div class="ttname"><a href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">BNN::prior_variance</a></div><div class="ttdeci">double prior_variance</div><div class="ttdoc">Variance for the prior distribution.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00095">bayes_net.hpp:95</a></div></div>
<div class="ttc" id="aclassBNN_html_aa9e8a5c9cea48ca7f5cf36da8806e0d9"><div class="ttname"><a href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">BNN::hidden_to_output_weights</a></div><div class="ttdeci">std::vector&lt; std::vector&lt; double &gt; &gt; hidden_to_output_weights</div><div class="ttdoc">Weights from hidden to output layer.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00110">bayes_net.hpp:110</a></div></div>
<div class="ttc" id="aclassBNN_html_acec9954182ed2dfcd18ca2290594a42b"><div class="ttname"><a href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">BNN::output_size</a></div><div class="ttdeci">int output_size</div><div class="ttdoc">Number of output units in the network.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00090">bayes_net.hpp:90</a></div></div>
<div class="ttc" id="aclassBNN_html_ad873f27be16165a38b4fc674bfd01edd"><div class="ttname"><a href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">BNN::output_biases</a></div><div class="ttdeci">std::vector&lt; double &gt; output_biases</div><div class="ttdoc">Biases for the output layer.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8hpp_source.html#l00115">bayes_net.hpp:115</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>, <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, <a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>, <a class="el" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>, <a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>, <a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>, <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>, and <a class="el" href="classBNN.html#a7250f3ccdea96a6107f43d9ba45b91e3">rng</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a709d59568bb9986baa79a9fcef808d45"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a709d59568bb9986baa79a9fcef808d45">&#9670;&nbsp;</a></span>activation_function()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double BNN::activation_function </td>
          <td>(</td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>x</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Activation function for the hidden layer. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">x</td><td>Input value </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Activated output </dd></dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00069">69</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;                                        {</div>
<div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;    <span class="comment">// Using sigmoid activation function for simplicity</span></div>
<div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;    <span class="keywordflow">return</span> 1.0 / (1.0 + std::exp(-x));</div>
<div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="a6fac631e4a1c0467e11c8089b72f7b9d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6fac631e4a1c0467e11c8089b72f7b9d">&#9670;&nbsp;</a></span>compute_loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double BNN::compute_loss </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute the negative log posterior (loss function) </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>Input features </td></tr>
    <tr><td class="paramname">y</td><td>True labels </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Negative log posterior </dd></dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00194">194</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;                                                                {</div>
<div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;    <span class="comment">// Negative log posterior (loss function)</span></div>
<div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;    <span class="keywordflow">return</span> -<a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a>(X, y) - <a class="code" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood</a>();</div>
<div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;}</div>
<div class="ttc" id="aclassBNN_html_a6c33b682dfa29b864d5ef002d58268fd"><div class="ttname"><a href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">BNN::log_likelihood</a></div><div class="ttdeci">double log_likelihood(const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y)</div><div class="ttdoc">Compute the log-likelihood of the data.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8cpp_source.html#l00156">bayes_net.cpp:156</a></div></div>
<div class="ttc" id="aclassBNN_html_a8322d4106f20c2a6e472f70db8da94e6"><div class="ttname"><a href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">BNN::prior_log_likelihood</a></div><div class="ttdeci">double prior_log_likelihood()</div><div class="ttdoc">Compute the log-likelihood of the prior distribution.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8cpp_source.html#l00115">bayes_net.cpp:115</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, and <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a18c2de8aeb520eb248e5ac8d0b7702dd">fit()</a>.</p>

</div>
</div>
<a id="a18c2de8aeb520eb248e5ac8d0b7702dd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18c2de8aeb520eb248e5ac8d0b7702dd">&#9670;&nbsp;</a></span>fit()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void BNN::fit </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>X_train</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>y_train</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>epochs</em> = <code>1000</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Train the Bayesian Neural Network. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X_train</td><td>Input training data </td></tr>
    <tr><td class="paramname">y_train</td><td>Target training data </td></tr>
    <tr><td class="paramname">epochs</td><td>Number of training epochs (default is 1000) </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00074">74</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;                          {</div>
<div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;    <span class="keyword">const</span> <span class="keywordtype">double</span> learning_rate = 0.01;</div>
<div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160; </div>
<div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> epoch = 0; epoch &lt; epochs; ++epoch) {</div>
<div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;        <a class="code" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights</a>(X_train, y_train, learning_rate);</div>
<div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160; </div>
<div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;        <span class="comment">// Print loss for monitoring training progress</span></div>
<div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        <span class="keywordflow">if</span> (epoch % 100 == 0) {</div>
<div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;            <span class="keywordtype">double</span> loss = <a class="code" href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">compute_loss</a>(X_train, y_train);</div>
<div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;            std::cout &lt;&lt; <span class="stringliteral">&quot;Epoch: &quot;</span> &lt;&lt; epoch &lt;&lt; <span class="stringliteral">&quot;, Loss: &quot;</span> &lt;&lt; loss &lt;&lt; std::endl;</div>
<div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;        }</div>
<div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;    }</div>
<div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;}</div>
<div class="ttc" id="aclassBNN_html_a190c79edcec186188ef96e30a1b099d9"><div class="ttname"><a href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">BNN::update_weights</a></div><div class="ttdeci">void update_weights(const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y, double learning_rate)</div><div class="ttdoc">Update weights using stochastic gradient descent.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8cpp_source.html#l00200">bayes_net.cpp:200</a></div></div>
<div class="ttc" id="aclassBNN_html_a6fac631e4a1c0467e11c8089b72f7b9d"><div class="ttname"><a href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">BNN::compute_loss</a></div><div class="ttdeci">double compute_loss(const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;X, const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;y)</div><div class="ttdoc">Compute the negative log posterior (loss function)</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8cpp_source.html#l00194">bayes_net.cpp:194</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">compute_loss()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="a6c33b682dfa29b864d5ef002d58268fd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6c33b682dfa29b864d5ef002d58268fd">&#9670;&nbsp;</a></span>log_likelihood()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double BNN::log_likelihood </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>y</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute the log-likelihood of the data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>Input features </td></tr>
    <tr><td class="paramname">y</td><td>True labels </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Log-likelihood of the data </dd></dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00156">156</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;                                                                  {</div>
<div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;    <span class="comment">// Compute log-likelihood of the data</span></div>
<div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;    <span class="keywordtype">double</span> <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> = 0.0;</div>
<div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160; </div>
<div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; X.size(); ++i) {</div>
<div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        <span class="comment">// Forward pass</span></div>
<div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        std::vector&lt;double&gt; hidden_output(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>);</div>
<div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++j) {</div>
<div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;            hidden_output[j] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;                std::inner_product(X[i].begin(),</div>
<div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;                                   X[i].end(),</div>
<div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;                                   <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[j].begin(),</div>
<div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;                                   0.0) +</div>
<div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;                <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[j]);</div>
<div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;        }</div>
<div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160; </div>
<div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;        std::vector&lt;double&gt; output(<a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>);</div>
<div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++j) {</div>
<div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;            output[j] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;                std::inner_product(hidden_output.begin(),</div>
<div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;                                   hidden_output.end(),</div>
<div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;                                   <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[j].begin(),</div>
<div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;                                   0.0) +</div>
<div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[j]);</div>
<div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;        }</div>
<div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160; </div>
<div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;        <span class="comment">// Log-likelihood for Gaussian noise</span></div>
<div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++j) {</div>
<div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;            <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> +=</div>
<div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;                -0.5 * std::log(2 * M_PI) - 0.5 * std::log(<a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>) -</div>
<div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;                0.5 * std::pow(y[i][j] - output[j], 2) / <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>;</div>
<div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;        }</div>
<div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;    }</div>
<div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160; </div>
<div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a>;</div>
<div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;}</div>
<div class="ttc" id="aclassBNN_html_a709d59568bb9986baa79a9fcef808d45"><div class="ttname"><a href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">BNN::activation_function</a></div><div class="ttdeci">double activation_function(double x)</div><div class="ttdoc">Activation function for the hidden layer.</div><div class="ttdef"><b>Definition:</b> <a href="bayes__net_8cpp_source.html#l00069">bayes_net.cpp:69</a></div></div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function()</a>, <a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>, <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, <a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>, <a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>, <a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>, <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>, and <a class="el" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">compute_loss()</a>, and <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>.</p>

</div>
</div>
<a id="add1980ab307e3c21ad1b49baac31bf5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#add1980ab307e3c21ad1b49baac31bf5f">&#9670;&nbsp;</a></span>predict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; double &gt; BNN::predict </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; double &gt; &amp;&#160;</td>
          <td class="paramname"><em>input_vector</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Predict the output for a given input. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">input_vector</td><td>Input data for prediction </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Predicted output vector </dd></dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00090">90</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;                                                                    {</div>
<div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="comment">// Forward pass</span></div>
<div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    std::vector&lt;double&gt; hidden_output(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>);</div>
<div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++i) {</div>
<div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;        hidden_output[i] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;            std::inner_product(input_vector.begin(),</div>
<div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;                               input_vector.end(),</div>
<div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;                               <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[i].begin(),</div>
<div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;                               0.0) +</div>
<div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;            <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[i]);</div>
<div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    }</div>
<div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160; </div>
<div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;    std::vector&lt;double&gt; output(<a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>);</div>
<div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++i) {</div>
<div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;        output[i] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;            std::inner_product(hidden_output.begin(),</div>
<div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;                               hidden_output.end(),</div>
<div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;                               <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[i].begin(),</div>
<div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;                               0.0) +</div>
<div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;            <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[i]);</div>
<div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;    }</div>
<div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160; </div>
<div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;    <span class="keywordflow">return</span> output;</div>
<div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function()</a>, <a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>, <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, <a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>, <a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>, <a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>, and <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>.</p>

</div>
</div>
<a id="a8322d4106f20c2a6e472f70db8da94e6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8322d4106f20c2a6e472f70db8da94e6">&#9670;&nbsp;</a></span>prior_log_likelihood()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double BNN::prior_log_likelihood </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute the log-likelihood of the prior distribution. </p>
<dl class="section return"><dt>Returns</dt><dd>Log-likelihood of the prior </dd></dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00115">115</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;                                 {</div>
<div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;    <span class="comment">// Compute log-likelihood of the prior</span></div>
<div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;    <span class="keywordtype">double</span> <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> = 0.0;</div>
<div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160; </div>
<div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="comment">// Prior for input-to-hidden weights</span></div>
<div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++i) {</div>
<div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>; ++j) {</div>
<div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;            <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> +=</div>
<div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                -0.5 *</div>
<div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;                (std::pow(<a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[i][j], 2) / <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a> +</div>
<div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;                 std::log(2 * M_PI * <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>));</div>
<div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;        }</div>
<div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    }</div>
<div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160; </div>
<div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;    <span class="comment">// Prior for hidden biases</span></div>
<div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++i) {</div>
<div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;        <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> +=</div>
<div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;            -0.5 * (std::pow(<a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[i], 2) / <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a> +</div>
<div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;                    std::log(2 * M_PI * <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>));</div>
<div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    }</div>
<div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160; </div>
<div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    <span class="comment">// Prior for hidden-to-output weights</span></div>
<div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++i) {</div>
<div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++j) {</div>
<div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;            <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> +=</div>
<div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;                -0.5 *</div>
<div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;                (std::pow(<a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[i][j], 2) / <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a> +</div>
<div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;                 std::log(2 * M_PI * <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>));</div>
<div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;        }</div>
<div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;    }</div>
<div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160; </div>
<div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;    <span class="comment">// Prior for output biases</span></div>
<div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++i) {</div>
<div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;        <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a> +=</div>
<div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;            -0.5 * (std::pow(<a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[i], 2) / <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a> +</div>
<div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;                    std::log(2 * M_PI * <a class="code" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>));</div>
<div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    }</div>
<div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160; </div>
<div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood</a>;</div>
<div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>, <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, <a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>, <a class="el" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>, <a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>, <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>, and <a class="el" href="classBNN.html#aa2f519827b4b67d66a569bc2c0a5ee7e">prior_variance</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6fac631e4a1c0467e11c8089b72f7b9d">compute_loss()</a>.</p>

</div>
</div>
<a id="a190c79edcec186188ef96e30a1b099d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a190c79edcec186188ef96e30a1b099d9">&#9670;&nbsp;</a></span>update_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">void BNN::update_weights </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>X</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; std::vector&lt; double &gt;&gt; &amp;&#160;</td>
          <td class="paramname"><em>y</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">double&#160;</td>
          <td class="paramname"><em>learning_rate</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Update weights using stochastic gradient descent. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">X</td><td>Input features </td></tr>
    <tr><td class="paramname">y</td><td>True labels </td></tr>
    <tr><td class="paramname">learning_rate</td><td>Learning rate for the update </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="bayes__net_8cpp_source.html#l00200">200</a> of file <a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a>.</p>
<div class="fragment"><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;                                               {</div>
<div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;    <span class="comment">// Update weights using stochastic gradient descent</span></div>
<div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; X.size(); ++i) {</div>
<div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;        <span class="comment">// Forward pass</span></div>
<div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;        std::vector&lt;double&gt; hidden_output(<a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>);</div>
<div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++j) {</div>
<div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;            hidden_output[j] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;                std::inner_product(X[i].begin(),</div>
<div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;                                   X[i].end(),</div>
<div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;                                   <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[j].begin(),</div>
<div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;                                   0.0) +</div>
<div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;                <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[j]);</div>
<div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;        }</div>
<div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160; </div>
<div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;        std::vector&lt;double&gt; output(<a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>);</div>
<div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++j) {</div>
<div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;            output[j] = <a class="code" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function</a>(</div>
<div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;                std::inner_product(hidden_output.begin(),</div>
<div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;                                   hidden_output.end(),</div>
<div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;                                   <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[j].begin(),</div>
<div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;                                   0.0) +</div>
<div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;                <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[j]);</div>
<div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;        }</div>
<div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160; </div>
<div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;        <span class="comment">// Backward pass (stochastic gradient descent)</span></div>
<div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++j) {</div>
<div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;            <span class="comment">// Gradient for output layer</span></div>
<div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;            <span class="keywordtype">double</span> output_gradient =</div>
<div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;                (y[i][j] - output[j]) * output[j] * (1.0 - output[j]);</div>
<div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160; </div>
<div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;            <span class="comment">// Update hidden-to-output weights</span></div>
<div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++k) {</div>
<div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;                <a class="code" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>[j][k] +=</div>
<div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;                    learning_rate * output_gradient * hidden_output[k];</div>
<div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;            }</div>
<div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160; </div>
<div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;            <span class="comment">// Update output biases</span></div>
<div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;            <a class="code" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>[j] += learning_rate * output_gradient;</div>
<div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;        }</div>
<div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160; </div>
<div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;        <span class="comment">// Backward pass for hidden layer</span></div>
<div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> j = 0; j &lt; <a class="code" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>; ++j) {</div>
<div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;            <span class="comment">// Gradient for hidden layer</span></div>
<div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;            <span class="keywordtype">double</span> hidden_gradient = 0.0;</div>
<div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; <a class="code" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>; ++k) {</div>
<div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;                hidden_gradient += <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[k][j] *</div>
<div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;                                   (y[i][k] - output[k]) * output[k] *</div>
<div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;                                   (1.0 - output[k]);</div>
<div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;            }</div>
<div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;            hidden_gradient *= hidden_output[j] * (1.0 - hidden_output[j]);</div>
<div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160; </div>
<div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;            <span class="comment">// Update input-to-hidden weights</span></div>
<div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;            <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; <a class="code" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>; ++k) {</div>
<div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;                <a class="code" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>[j][k] +=</div>
<div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;                    learning_rate * hidden_gradient * X[i][k];</div>
<div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;            }</div>
<div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160; </div>
<div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;            <span class="comment">// Update hidden biases</span></div>
<div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;            <a class="code" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>[j] += learning_rate * hidden_gradient;</div>
<div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;        }</div>
<div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;    }</div>
<div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;}</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="classBNN.html#a709d59568bb9986baa79a9fcef808d45">activation_function()</a>, <a class="el" href="classBNN.html#a018666fad85e1ff23fa4e2130694713a">hidden_biases</a>, <a class="el" href="classBNN.html#a24f4cd9fa8b68acc0ab88f78e0a433f2">hidden_size</a>, <a class="el" href="classBNN.html#aa9e8a5c9cea48ca7f5cf36da8806e0d9">hidden_to_output_weights</a>, <a class="el" href="classBNN.html#a279dcd56ad5a75e42c2f39491656db64">input_size</a>, <a class="el" href="classBNN.html#a9a8dbbcda35e722fb044192fd9ce6525">input_to_hidden_weights</a>, <a class="el" href="classBNN.html#ad873f27be16165a38b4fc674bfd01edd">output_biases</a>, and <a class="el" href="classBNN.html#acec9954182ed2dfcd18ca2290594a42b">output_size</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a18c2de8aeb520eb248e5ac8d0b7702dd">fit()</a>.</p>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a018666fad85e1ff23fa4e2130694713a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a018666fad85e1ff23fa4e2130694713a">&#9670;&nbsp;</a></span>hidden_biases</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; BNN::hidden_biases</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Biases for the hidden layer. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00105">105</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="a24f4cd9fa8b68acc0ab88f78e0a433f2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a24f4cd9fa8b68acc0ab88f78e0a433f2">&#9670;&nbsp;</a></span>hidden_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int BNN::hidden_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of hidden units in the network. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00085">85</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="aa9e8a5c9cea48ca7f5cf36da8806e0d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa9e8a5c9cea48ca7f5cf36da8806e0d9">&#9670;&nbsp;</a></span>hidden_to_output_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;double&gt; &gt; BNN::hidden_to_output_weights</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Weights from hidden to output layer. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00110">110</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="a279dcd56ad5a75e42c2f39491656db64"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a279dcd56ad5a75e42c2f39491656db64">&#9670;&nbsp;</a></span>input_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int BNN::input_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of input features. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00080">80</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="a9a8dbbcda35e722fb044192fd9ce6525"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a8dbbcda35e722fb044192fd9ce6525">&#9670;&nbsp;</a></span>input_to_hidden_weights</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;std::vector&lt;double&gt; &gt; BNN::input_to_hidden_weights</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Weights from input to hidden layer. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00100">100</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="ad873f27be16165a38b4fc674bfd01edd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad873f27be16165a38b4fc674bfd01edd">&#9670;&nbsp;</a></span>output_biases</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt;double&gt; BNN::output_biases</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Biases for the output layer. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00115">115</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="acec9954182ed2dfcd18ca2290594a42b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acec9954182ed2dfcd18ca2290594a42b">&#9670;&nbsp;</a></span>output_size</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int BNN::output_size</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Number of output units in the network. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00090">90</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>, <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, <a class="el" href="classBNN.html#add1980ab307e3c21ad1b49baac31bf5f">predict()</a>, <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>, and <a class="el" href="classBNN.html#a190c79edcec186188ef96e30a1b099d9">update_weights()</a>.</p>

</div>
</div>
<a id="aa2f519827b4b67d66a569bc2c0a5ee7e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa2f519827b4b67d66a569bc2c0a5ee7e">&#9670;&nbsp;</a></span>prior_variance</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">double BNN::prior_variance</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Variance for the prior distribution. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00095">95</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6c33b682dfa29b864d5ef002d58268fd">log_likelihood()</a>, and <a class="el" href="classBNN.html#a8322d4106f20c2a6e472f70db8da94e6">prior_log_likelihood()</a>.</p>

</div>
</div>
<a id="a7250f3ccdea96a6107f43d9ba45b91e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7250f3ccdea96a6107f43d9ba45b91e3">&#9670;&nbsp;</a></span>rng</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">std::mt19937 BNN::rng</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Mersenne Twister random number generator. </p>

<p class="definition">Definition at line <a class="el" href="bayes__net_8hpp_source.html#l00120">120</a> of file <a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a>.</p>

<p class="reference">Referenced by <a class="el" href="classBNN.html#a6453c5fa070a02120d9058392a1dc054">BNN()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>include/openGPMP/ml/<a class="el" href="bayes__net_8hpp_source.html">bayes_net.hpp</a></li>
<li>modules/ml/<a class="el" href="bayes__net_8cpp_source.html">bayes_net.cpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
